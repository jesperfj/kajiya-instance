user app;
worker_processes  1;

error_log  /var/log/nginx/error.log;
pid        /var/run/nginx.pid;

events {
    worker_connections  1024;
    use epoll;
    # multi_accept on;
}

http {
    include       /etc/nginx/mime.types;

    # as recommended by http://unicorn.bogomips.org/examples/nginx.conf
    default_type  application/octet-stream;


    access_log	/var/log/nginx/access.log;

    sendfile       on;
    # as recommended by http://unicorn.bogomips.org/examples/nginx.conf
    tcp_nopush     on;


    # as recommended by http://unicorn.bogomips.org/examples/nginx.conf
    # except kept MSIE line as original

    # we haven't checked to see if Rack::Deflate on the app server is
    # faster or not than doing compression via nginx.  It's easier
    # to configure it all in one place here for static files and also
    # to disable gzip for clients who don't get gzip/deflate right.
    # There are other gzip settings that may be needed used to deal with
    # bad clients out there, see http://wiki.nginx.org/NginxHttpGzipModule
    gzip on;
    gzip_http_version 1.0;
    gzip_proxied any;
    gzip_min_length 500;
    gzip_disable "MSIE [1-6]\.(?!.*SV1)";
    gzip_types text/plain text/html text/xml text/css
               text/comma-separated-values
               text/javascript application/x-javascript
               application/atom+xml;


    #keepalive_timeout  0;
    # this is set in the server section copied in from http://unicorn.bogomips.org/examples/nginx.conf
    # so commenting out here.
    #keepalive_timeout  65;
  
    # as recommended by http://unicorn.bogomips.org/examples/nginx.conf
    tcp_nodelay        off;

    # don't use any of these:
    # include /etc/nginx/conf.d/*.conf;
    # include /etc/nginx/sites-enabled/*;

  

    # this can be any application server, not just Unicorn/Rainbows!
    upstream app_server {
        # fail_timeout=0 means we always retry an upstream even if it failed
        # to return a good HTTP response (in case the Unicorn master nukes a
        # single worker for timing out).

        # for UNIX domain socket setups:
        # server unix:/tmp/.sock fail_timeout=0;

        # for TCP setups, point these to your backend servers
        # for now, we'll have unicorn listen on a port and forward to it.
        # later we'll consider unix socket
        server 127.0.0.1:8080 fail_timeout=0;
        # server 192.168.0.8:8080 fail_timeout=0;
        # server 192.168.0.9:8080 fail_timeout=0;
    }

    server {
        # enable one of the following if you're on Linux or FreeBSD
        # listen 80 default deferred; # for Linux
        # listen 80 default accept_filter=httpready; # for FreeBSD
	listen 8000 default deferred


        # If you have IPv6, you'll likely want to have two separate listeners.
        # One on IPv4 only (the default), and another on IPv6 only instead
        # of a single dual-stack listener.  A dual-stack listener will make
        # for ugly IPv4 addresses in $remote_addr (e.g ":ffff:10.0.0.1"
        # instead of just "10.0.0.1") and potentially trigger bugs in
        # some software.
        # listen [::]:80 ipv6only=on; # deferred or accept_filter recommended

        #client_max_body_size 4G;
        server_name _;

        # ~2 seconds is often enough for most folks to parse HTML/CSS and
        # retrieve needed images/icons/frames, connections are cheap in
        # nginx so increasing this is generally safe...
        keepalive_timeout 5;

        # path for static files
        root /home/app/public;

        # Prefer to serve static files directly from nginx to avoid unnecessary
        # data copies from the application server.
        #
        # try_files directive appeared in in nginx 0.7.27 and has stabilized
        # over time.  Older versions of nginx (e.g. 0.6.x) requires
        # "if (!-f $request_filename)" which was less efficient:
        # http://bogomips.org/unicorn.git/tree/examples/nginx.conf?id=v3.3.1#n127
        try_files $uri/index.html $uri.html $uri @app;

        location @app {
          # an HTTP header important enough to have its own Wikipedia entry:
          #   http://en.wikipedia.org/wiki/X-Forwarded-For
          proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;

          # enable this if you forward HTTPS traffic to unicorn,
          # this helps Rack set the proper URL scheme for doing redirects:
          # proxy_set_header X-Forwarded-Proto $scheme;

          # pass the Host: header from the client right along so redirects
          # can be set properly within the Rack application
          proxy_set_header Host $http_host;

          # we don't want nginx trying to do something clever with
          # redirects, we set the Host: header above already.
          proxy_redirect off;

          # set "proxy_buffering off" *only* for Rainbows! when doing
          # Comet/long-poll/streaming.  It's also safe to set if you're using
          # only serving fast clients with Unicorn + nginx, but not slow
          # clients.  You normally want nginx to buffer responses to slow
          # clients, even with Rails 3.1 streaming because otherwise a slow
          # client can become a bottleneck of Unicorn.
          #
          # The Rack application may also set "X-Accel-Buffering (yes|no)"
          # in the response headers do disable/enable buffering on a
          # per-response basis.
          # proxy_buffering off;

          proxy_pass http://app_server;
        }

        # Rails error pages
        error_page 500 502 503 504 /500.html;
        location = /500.html {
          root /path/to/app/current/public;
        }
    }

}

# mail {
#     # See sample authentication script at:
#     # http://wiki.nginx.org/NginxImapAuthenticateWithApachePhpScript
# 
#     # auth_http localhost/auth.php;
#     # pop3_capabilities "TOP" "USER";
#     # imap_capabilities "IMAP4rev1" "UIDPLUS";
# 
#     server {
#         listen     localhost:110;
#         protocol   pop3;
#         proxy      on;
#     }
# 
#     server {
#         listen     localhost:143;
#         protocol   imap;
#         proxy      on;
#     }
# }
